# speech-recognition

## Todo

- Построить и сохранить спектрограммы (сохранит ли их препроцессинг, который мы пихаем в dataloader?)

- Решить, сколько классов оставляем для обучения. На это влияют факторы:
    - сколько времени занимает построение спектрограмм
    - в датасете есть слова с ~2300 записями и с ~1700 записями (см. SpeechCommands README.md). Нужно ли нам оставлять вторую часть слов?
    - будем ли применять downsampling до 8000 Гц? Это должно ускорить обработку без существенных потерь в классификации.

- Заменить GreedyDecoder на beam search

- Поискать улучшения архитектуры: гугл, kaggle


## Done

1. Поменяли датасет на SpeechCommands

2. Архитектура: CNN + BiGRU

## Теория

1. Зачем нам conv2d слой перед CNN?

2. Разобраться, как работают CER, CTC loss